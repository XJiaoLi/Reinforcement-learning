# 表格型方法

使用查找表的强化学习方法称为表格型方法（tabular method），如蒙特卡洛、Q学习和Sarsa

## 马尔可夫决策过程

马尔可夫决策过程也是强化学习里面一个非常基本的学习框架。状态、动作、状态转移概率和奖励$(S,A,P,R)$,这4个合集就构成了强化学习马尔可夫决策过程的四元组，后面也可能会再加上折扣因子构成五元组。

状态转移概率是具有马尔可夫性质的（系统下一时刻的状态仅由当前时刻的状态决定，不依赖于以往任何状态）。

### 有模型

环境可以用概率函数$P[s_{t+1},r_t|s_t,a_t]$和奖励函数$R[s_t,a_t]$来描述。概率函数就是状态转移的概率，它反映的是环境的随机性。

- 如果知道概率函数和奖励函数，马尔可夫决策过程就是已知的，我们可以通过策略迭代和价值迭代来找最佳的策略。
- 如果知道环境的状态转移概率和奖励函数，可以认为这个环境是已知的，这时可以用动态规划算法去计算。

### 免模型

很多强化学习的经典算法都是免模型的，也就是环境是未知的，也就是这一系列的决策的概率函数和奖励函数是未知的，这就是有模型与免模型的最大的区别。

强化学习可以应用于完全未知的和随机的环境。强化学习像人类一样学习，人类通过尝试不同的路来学习，通过尝试不同的路，人类可以慢慢地了解哪个状态会更好。强化学习用价值函数$V(S)$来表示状态是好的还是坏的，用 Q 函数来判断在什么状态下采取什么动作能够取得最大奖励，即用 Q 函数来表示状态-动作值。

![免模型试错探索图](https://datawhalechina.github.io/easy-rl/img/ch3/3.3.png)



#### 参考文献

1、[蘑菇书EasyRL](https://datawhalechina.github.io/easy-rl/#/)







